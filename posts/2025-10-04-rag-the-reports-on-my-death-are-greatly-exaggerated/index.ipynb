{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0167ff00",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"RAG: The reports of my death are greatly exaggerated\"\n",
    "date: \"2025-10-04\"\n",
    "abstract: RAG is dead. I've struggled with making vector search and emedding techiques work for searching large documents, and maybe context windows and agents have made it obsolete. Or maybe not? Long live RAG?\n",
    "draft: false\n",
    "publish: true\n",
    "callout-appearance: simple\n",
    "categories: [RAG, AI, LLM, vectors, embedding, cosine similarity]\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdb6676",
   "metadata": {},
   "source": [
    "A colleague at work sent me a blog post that trended on Hacker News: [The RAG Obituary: Killed by Agents, Buried by Context Windows](https://www.nicolasbustamante.com/p/the-rag-obituary-killed-by-agents), by \n",
    "Nicolas Bustamante.\n",
    "\n",
    "The post postulates the decline of Retrieval-Augmented Generation (RAG) in AI, suggesting that the rise of agent-based techniques, like using Claude Code, is making RAG obsolete. He starts with a great explanation of what RAG was originally meant to solve: How to get LLMs to work with large documents, given their limited context windows (their short term memory).\n",
    "\n",
    "> Consider the numbers: A single SEC 10-K filing contains approximately 51,000 tokens (130+ pages).\n",
    ">\n",
    "> With [an LLM with a context window of] 8,192 tokens, you could see less than 16% of a 10-K filing. It's like reading a financial report through a keyhole!\n",
    "\n",
    "\n",
    "The most interesting part of the post is the deep dive into RAG itself, how mixing embedding techniques (which I explored [here](https://geirfreysson.com/posts/2025-01-19-playing-with-embeddings/index.html) and [here](https://geirfreysson.com/posts/2025-01-25-comparing-embedding-models/index.html)) with traditional keyword search yields better results than either technique in isolation.\n",
    "\n",
    "In the past I've found it hard to get usable results in search by converting sentences to vectors and then comparing them with cosine similarity, the cornerstone of RAG. But mixing that with trad-search sounds promising.\n",
    "\n",
    "I'm on the fence about the demise of RAG. I haven't used it successfully and I know a lot of people who are struggling with RAG implementations, but I also hear stories about people using it successfully. In the [Y-Combinator interview](https://www.ycombinator.com/library/Mq-how-this-25-year-old-built-a-675m-legal-ai-startup-with-no-legal-experience) with LegalTech startup [Legora](https://legora.com/) it sounds like they are using RAG very successfully.\n",
    "\n",
    "For a lively discussion about RAG, its demise or usefulness, check out the Hacker News thread: [The RAG Obituary: Killed by Agents, Buried by Context Windows](https://news.ycombinator.com/item?id=45439997).\n",
    "\n",
    "The jury is out on RAG. I'm going to try it out again, mixed with trad-search, and report back.\n",
    "\n",
    "RAG is dead. Long live RAG!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
