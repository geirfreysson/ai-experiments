{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0167ff00",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Revisiting RAG\"\n",
    "date: \"2025-10-05\"\n",
    "draft: \"true\"\n",
    "publish: \"false\"\n",
    "image: \"\" \n",
    "callout-appearance: simple\n",
    "categories: []\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdb6676",
   "metadata": {},
   "source": [
    "A colleague at work send me a blog post that trended briefly on Hacker News: [The RAG Obituary: Killed by Agents, Buried by Context Windows](https://www.nicolasbustamante.com/p/the-rag-obituary-killed-by-agents), by \n",
    "Nicolas Bustamante\n",
    "\n",
    "The post postulates the decline of Retrieval-Augmented Generation (RAG) in AI, suggesting that the rise of agent-based techniques, like ausing Claude Code, is making RAG obsolete. He starts with a great explanation of what RAG was originally meant to solve: How to get LLMs to work with large documents, given their limited context windows (their short term memory).\n",
    "\n",
    "> Consider the numbers: A single SEC 10-K filing contains approximately 51,000 tokens (130+ pages).\n",
    ">\n",
    "> With [an LLM with a context window of] 8,192 tokens, you could see less than 16% of a 10-K filing. Itâ€™s like reading a financial report through a keyhole!\n",
    "\n",
    "\n",
    "The most interesting part of the post is the deep dive into RAG itself, how mixing embedding techniques (which I explored [here](https://geirfreysson.com/posts/2025-01-19-playing-with-embeddings/index.html) and [here](https://geirfreysson.com/posts/2025-01-25-comparing-embedding-models/index.html)) with traditional keyword search yields better results than either technique in isolation.\n",
    "\n",
    "In the past I've found it hard to get usable results in search by converting sentences to vectors and then finding their similarity with cosine distance, the cornerstone of RAG. We've actually to [sending our search queries directly to an LLM](https://geirfreysson.com/posts/2025-04-20-using-vector-comparison-vs-raw-llm-requests-in-semantic-search/index.html), which has given us better results.\n",
    "\n",
    "On Monday, we are going to try the Hybrid approach.\n",
    "\n",
    "I'm on the fench about the demise of RAG. I haven't used it successfully and I know a lot of pepole who are in pain, but I also hear stories about people using it successfully, like this Y Combinator podcast about LegalTech startup [Legora](https://legora.com/). Surely they are using RAG?\n",
    "\n",
    "For a lively discussion about RAG, it's demise or usefulness, check out the Hacker News thread: [The RAG Obituary: Killed by Agents, Buried by Context Windows](https://news.ycombinator.com/item?id=45439997)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
