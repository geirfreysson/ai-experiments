{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b6552402",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"The AI agent version of hello world in different frameworks\"\n",
    "date: \"2025-11-16\"\n",
    "draft: \"false\"\n",
    "publish: \"true\"\n",
    "callout-appearance: simple\n",
    "categories: [agents, langchain, llamaindex, smolagents]\n",
    "execute:\n",
    "  freeze: auto\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cac75aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "import os\n",
    "os.environ[\"RICH_WIDTH\"] = \"50\"   # 80 cols; pick what you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daeee1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/geirfreysson/Code/ai-experiments/posts/2025-11-09-the-ai-agent-version-of-hello-world-in-different-frameworks./.venv/bin/python: No module named uv\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "%uv pip install smolagents, litellm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e030b1b9",
   "metadata": {},
   "source": [
    "For [my talk at PyData London](https://geirfreysson.com/posts/2025-11-03-reliable-data-driven-ai-agents/index.html), I was trying to explain what a tool calling agent is, and created the simplest version I could think of. It's an agent that has two functions, `sum` and `divide`, and I asked it to calculate the average of a sequence of numbers.\n",
    "\n",
    "Obviously, any modern language model can do this, but it's still an interesting excersise to understand how agents work. I've worked with Hugging Face's smolagents a lot recently, but I wanted to compare it to LlamaIndex and LangChain, two of the most popular frameworks.\n",
    "\n",
    "In the outset, I thought the libraries would all have a different approach. Last time I tried LanngChain, for example, it was unwieldy and the imports had weird names from seemingly unrelated libraries. But to my surprise, the three frameworks had a very similar approach to building this simple agent. In the outset, I was going to compare what library made it easiest to get started, but in the end, they were all very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b32fc9",
   "metadata": {},
   "source": [
    "## smolagents\n",
    "\n",
    "I love the smolagents library from Hugging Face. Because it's such a small library, it makes it easy to understand exactly what is going on. I also highly recommend their [Agent's Course](https://huggingface.co/learn/agents-course/en/unit0/introduction) for anyone getting into building agents.\n",
    "\n",
    "Smolagents supports both function decorators like `@tool` and defining tools as a class. The example below only shows the former."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e3838e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">What is the average of 10, 20, 30, 40, and 50?</span>                                                                  <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ LiteLLMModel - gpt-4o-mini ────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mWhat is the average of 10, 20, 30, 40, and 50?\u001b[0m                                                                  \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m LiteLLMModel - gpt-4o-mini \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step 1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep 1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'sum_numbers' with arguments: {'numbers': [10, 20, 30, 40, 50]}                                   │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'sum_numbers' with arguments: {'numbers': [10, 20, 30, 40, 50]}                                   │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Observations: 150\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Observations: 150\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 1.15 seconds| Input tokens: 1,070 | Output tokens: 22]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 1.15 seconds| Input tokens: 1,070 | Output tokens: 22]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step 2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep 2\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'divide_sum' with arguments: {'total': 150, 'length': 5}                                          │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'divide_sum' with arguments: {'total': 150, 'length': 5}                                          │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Observations: 30.0\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Observations: 30.0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 2: Duration 1.20 seconds| Input tokens: 2,218 | Output tokens: 40]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 2: Duration 1.20 seconds| Input tokens: 2,218 | Output tokens: 40]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step 3</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep 3\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'final_answer' with arguments: {'answer': '30.0'}                                                 │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'final_answer' with arguments: {'answer': '30.0'}                                                 │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Observations: 30.0\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Observations: 30.0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Final answer: 30.0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mFinal answer: 30.0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 3: Duration 0.91 seconds| Input tokens: 3,438 | Output tokens: 56]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 3: Duration 0.91 seconds| Input tokens: 3,438 | Output tokens: 56]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'30.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from smolagents import ToolCallingAgent, LiteLLMModel, tool\n",
    "\n",
    "@tool\n",
    "def sum_numbers(numbers: list[float]) -> float:\n",
    "    \"\"\"\n",
    "    PLEASE Calculate the sum of a list of numbers.\n",
    "\n",
    "    Args:\n",
    "        numbers: A list of numbers to sum\n",
    "    \"\"\"\n",
    "    return sum(numbers)\n",
    "\n",
    "@tool\n",
    "def divide_sum(total: float, length: int) -> float:\n",
    "    \"\"\"\n",
    "    Divide a sum by a length to get the average.\n",
    "\n",
    "    Args:\n",
    "        total: The sum/total to divide\n",
    "        length: The number to divide by (typically the count of numbers)\n",
    "    \"\"\"\n",
    "    return total / length\n",
    "\n",
    "model = LiteLLMModel(model_id=\"gpt-4o-mini\")\n",
    "agent = ToolCallingAgent(tools=[sum_numbers, divide_sum], model=model)\n",
    "agent.run(\"What is the average of 10, 20, 30, 40, and 50?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f63a9d",
   "metadata": {},
   "source": [
    "## LlamaIndex\n",
    "\n",
    "LlamaIndex was one of the first AI assistant frameworks I came across, although I opted for LangChain when I was exploring [searching through PDFs with embeddings](https://geirfreysson.com/posts/2025-02-09-llm-app-to-search-through-pdf-documents/index.html), the corner stone of RAG. I can't say I'm a fan of this code:\n",
    "```\n",
    "from llama_index.core.tools import FunctionTool\n",
    "sum_tool = FunctionTool.from_defaults(fn=sum_numbers)\n",
    "```\n",
    "But maybe LlamaIndex also has decorators, I haven't looked that closely. And this is no cardinal sin if LlamaIndex is otherwise strong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3028406d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The current language of the user is: English. I need to use tools to calculate the average of the numbers provided.\n",
      "Action: sum_numbers\n",
      "Action Input: {\"numbers\":[10,20,30,40,50]}Thought: I have the sum of the numbers, which is 150. Now I need to divide this sum by the count of the numbers to find the average.\n",
      "Action: divide_sum\n",
      "Action Input: {'total': 150, 'length': 5}Thought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: The average of 10, 20, 30, 40, and 50 is 30.0.\n",
      "\n",
      "Final response: The average of 10, 20, 30, 40, and 50 is 30.0.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.agent.workflow import ReActAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "def sum_numbers(numbers: list[float]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the sum of a list of numbers.\n",
    "\n",
    "    Args:\n",
    "        numbers: A list of numbers to sum\n",
    "    \"\"\"\n",
    "    return sum(numbers)\n",
    "\n",
    "def divide_sum(total: float, length: int) -> float:\n",
    "    \"\"\"\n",
    "    Divide a sum by a length to get the average.\n",
    "\n",
    "    Args:\n",
    "        total: The sum/total to divide\n",
    "        length: The number to divide by (typically the count of numbers)\n",
    "    \"\"\"\n",
    "    return total / length\n",
    "\n",
    "# Create FunctionTools from the functions\n",
    "sum_tool = FunctionTool.from_defaults(fn=sum_numbers)\n",
    "divide_tool = FunctionTool.from_defaults(fn=divide_sum)\n",
    "\n",
    "# Create LLM and agent\n",
    "llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "agent = ReActAgent(tools=[sum_tool, divide_tool], llm=llm, verbose=True)\n",
    "\n",
    "# Run the agent and show intermediate steps\n",
    "from llama_index.core.agent.workflow import AgentStream\n",
    "\n",
    "handler = agent.run(\"What is the average of 10, 20, 30, 40, and 50?\")\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, AgentStream):\n",
    "        print(f\"{ev.delta}\", end=\"\", flush=True)\n",
    "response = await handler\n",
    "print(f\"\\n\\nFinal response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d64d37",
   "metadata": {},
   "source": [
    "## LangChain\n",
    "\n",
    "Finally, I tried LangChain, which seems to have the most adoption in the industry. Their approach is similar to the others, using `@tool` decoratros like smolagents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96f4a24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the average of 10, 20, 30, 40, and 50?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sum_numbers (call_oq9YUUKfb2GrNINTJ9H8kc2z)\n",
      " Call ID: call_oq9YUUKfb2GrNINTJ9H8kc2z\n",
      "  Args:\n",
      "    numbers: [10, 20, 30, 40, 50]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sum_numbers\n",
      "\n",
      "150.0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  divide_sum (call_2Df47jyASnaXh6apmKovGbhJ)\n",
      " Call ID: call_2Df47jyASnaXh6apmKovGbhJ\n",
      "  Args:\n",
      "    total: 150\n",
      "    length: 5\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: divide_sum\n",
      "\n",
      "30.0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The average of 10, 20, 30, 40, and 50 is 30.0.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "@tool\n",
    "def sum_numbers(numbers: list[float]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the sum of a list of numbers.\n",
    "\n",
    "    Args:\n",
    "        numbers: A list of numbers to sum\n",
    "    \"\"\"\n",
    "    return sum(numbers)\n",
    "\n",
    "@tool\n",
    "def divide_sum(total: float, length: int) -> float:\n",
    "    \"\"\"\n",
    "    Divide a sum by a length to get the average.\n",
    "\n",
    "    Args:\n",
    "        total: The sum/total to divide\n",
    "        length: The number to divide by (typically the count of numbers)\n",
    "    \"\"\"\n",
    "    return total / length\n",
    "\n",
    "# Create LLM and agent\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "agent = create_agent(model, [sum_numbers, divide_sum])\n",
    "\n",
    "# Run the agent with streaming to see intermediate steps\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [(\"user\", \"What is the average of 10, 20, 30, 40, and 50?\")]},\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc90f953",
   "metadata": {},
   "source": [
    "## Running the examples on your machine\n",
    "To run the examples on your machine, install uv and run the following commands in your terminal:\n",
    "\n",
    "```\n",
    "uv run https://raw.githubusercontent.com/geirfreysson/ai-experiments/main/posts/2025-11-09-the-ai-agent-version-of-hello-world-in-different-frameworks/two_tool_agent_llamaindex_script.py\n",
    "\n",
    "uv run https://raw.githubusercontent.com/geirfreysson/ai-experiments/main/posts/2025-11-09-the-ai-agent-version-of-hello-world-in-different-frameworks/two_tool_agent_langgraph.py\n",
    "\n",
    "uv run https://raw.githubusercontent.com/geirfreysson/ai-experiments/main/posts/2025-11-09-the-ai-agent-version-of-hello-world-in-different-frameworks/two_tool_agent.py\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "I need to explore these frameworks further to form an opinion of them. I thought I was going to walk away saying smolagents is the simplest one to get started with, but the other libraries approach is very similar. Smolagents might still have the smallest codebase, which makes it a better framework for learning about agents, but I also need to explore that further.\n",
    "\n",
    "If you want to explore further, the above is also available as standalone scripts, which you can run with `uv`, so you don't need to install any libraries.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
