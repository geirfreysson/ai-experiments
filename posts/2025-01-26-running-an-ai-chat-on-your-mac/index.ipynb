{
 "cells": [
  {
   "cell_type": "raw",
   "id": "74f249ad",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Chat with the hottest LLM model on your Mac - just don't ask about Tiananmen Square\"\n",
    "date: \"2025-01-26\"\n",
    "draft: \"false\"\n",
    "publish: \"false\"\n",
    "image: \"deepseek-r1-screenshot.png\" \n",
    "callout-appearance: simple\n",
    "categories: [llm, webui, ollama]\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f86905",
   "metadata": {},
   "source": [
    "LLM models that run on your local machine are becoming better and better. Indeed, thanks to the AI arms race, these models will soon be good enough for a vast majority of tasks required by individuals and companies that want to leverage language models. I've [already covered](/posts/2025-01-19-playing-with-embeddings/index.html#using-local-llms) how to install a LLM locally using Ollama, but how do you chat with the model? Enter WebUI.\n",
    "\n",
    "I had trouble running WebUI via their first recommended installation option, Docker, but luckily they provide a guide on how to install it via the new python package manager uv.\n",
    "\n",
    "```{.terminal}\n",
    "DATA_DIR=~/.open-webui uvx --python 3.11 open-webui@latest serve\n",
    "```\n",
    "\n",
    ":::{.callout-note}\n",
    "The easiest way to chat with a local model is LM Studio. It integrates a GUI with the ability to download models via a point-and-click interface. I'm more interested in an option that can become part of a product and is more customisable.\n",
    ":::\n",
    "\n",
    "### It's alive\n",
    "\n",
    "![](webui-screenshot.png)\n",
    "\n",
    "\n",
    "### Chatting with the hottest model around: \n",
    "\n",
    "::: {layout-ncol=2}\n",
    "\n",
    "![Llama3.1 gives a long explanation about what happened in Tiananmen Square](llama3_1-tiananmen-square.png){.lightbox}\n",
    "\n",
    "![Deepseek](deepseek-tiananmen-square.png){.lightbox}\n",
    ":::\n",
    "\n",
    "https://github.com/deepseek-ai/DeepSeek-R1\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
